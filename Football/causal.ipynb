{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from find import *\n",
    "df = pd.read_csv('match_event.csv')\n",
    "# Only consider events that are successful\n",
    "df = searchDF(df, [('is_success', 't')])\n",
    "df['eventsec'] = df['eventsec'].apply(lambda x: round(x))\n",
    "df.fillna({'eventname':'None'}, inplace=True)\n",
    "df.fillna({'action':'None'}, inplace=True)\n",
    "df.fillna({'modifier':'None'}, inplace=True)\n",
    "df = df.drop(columns=['is_success'])\n",
    "\n",
    "match_period = df['matchperiod'].unique()\n",
    "match_map = {'1H': 1,\n",
    "             '2H': 2}\n",
    "\n",
    "event_df = pd.DataFrame(columns=['id', 'event'])\n",
    "events = df['eventname'].unique()\n",
    "events = np.sort(events)\n",
    "event_map = {events[i]: i for i in range(len(events))}\n",
    "event_df['eventname'] = events\n",
    "event_df['id'] = event_map.values()\n",
    "event_df.to_csv('fkeys/event.csv', index=False)\n",
    "\n",
    "action_df = pd.DataFrame(columns=['id', 'action'])\n",
    "actions = df['action'].unique()\n",
    "actions = np.sort(actions)\n",
    "action_map = {actions[i]: i for i in range(len(actions))}\n",
    "action_df['action'] = actions\n",
    "action_df['id'] = action_map.values()\n",
    "action_df.to_csv('fkeys/action.csv', index=False)\n",
    "\n",
    "modifier_df = pd.DataFrame(columns=['id', 'modifier'])\n",
    "modifiers = df['modifier'].unique()\n",
    "modifiers = np.sort(modifiers)\n",
    "modifier_map = {modifiers[i]: i for i in range(len(modifiers))}\n",
    "modifier_df['modifier'] = modifiers\n",
    "modifier_df['id'] = modifier_map.values()\n",
    "modifier_df.to_csv('fkeys/modifier.csv', index=False)\n",
    "\n",
    "df['matchperiod'] = df['matchperiod'].apply(lambda x: match_map[x])\n",
    "df['eventname'] = df['eventname'].apply(lambda x: event_map[x])\n",
    "df['action'] = df['action'].apply(lambda x: action_map[x])\n",
    "df['modifier'] = df['modifier'].apply(lambda x: modifier_map[x])\n",
    "\n",
    "df.rename(columns={'eventname':'event'}, inplace=True)\n",
    "df.rename(columns={'matchperiod':'match_period'}, inplace=True)\n",
    "df.rename(columns={'eventsec':'time'}, inplace=True)\n",
    "df.rename(columns={'modifier':'action_result'}, inplace=True)\n",
    "df.rename(columns={'players_id':'player_id'}, inplace=True)\n",
    "\n",
    "df = df.sort_values(by=['id'])\n",
    "df.to_csv('success.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "df = pd.read_csv('success.csv')\n",
    "# for each match_id, generate a df and save to csv under matches folder, filename should be 'match_{match_id}.csv'\n",
    "match_ids = df['match_id'].unique()\n",
    "for match_id in match_ids:\n",
    "    match_df = searchDF(df, [('match_id', match_id)])\n",
    "    first_half = match_df[match_df['match_period'] == 1]\n",
    "    max_time = first_half['time'].max()\n",
    "    match_df.loc[match_df['match_period'] == 2, 'time'] += max_time\n",
    "    match_df = match_df.drop(columns=['match_id', 'match_period', 'club_id'])\n",
    "    min_time = match_df['time'].min()\n",
    "    match_df['time'] -= min_time\n",
    "    match_df['time'] = match_df['time']//60 # convert to minutes\n",
    "    match_df = match_df.sort_values(by=['player_id', 'time'])\n",
    "    path = f'matches/match_{match_id}'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    match_df.to_csv(f'matches/match_{match_id}/match_data.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START HERE\n",
    "df = pd.read_csv('matches/match_0/match_data.csv')\n",
    "df = df.drop(columns=['id', 'event',\n",
    "             'action_result', 'x_begin', 'y_begin', 'x_end', 'y_end'])\n",
    "# df.to_csv('matches/match_0/match_data_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from find import *\n",
    "# df = pd.read_csv('matches/match_0/match_data_2.csv')\n",
    "# Expand action column according to fkeys/action.csv to use one-hot encoding\n",
    "action_df = pd.read_csv('fkeys/action.csv')\n",
    "action_map = {action_df['action'][i]: action_df['id'][i]\n",
    "              for i in range(len(action_df))}\n",
    "columns = ['player_id', 'time']\n",
    "columns.extend(action_df['action'].values)\n",
    "new_df = pd.DataFrame(columns=columns)\n",
    "min_time = df['time'].min()\n",
    "max_time = df['time'].max()\n",
    "# Each player will have a row from min_time to max_time\n",
    "# If the player does not have an action at time t, then all action columns will be 0\n",
    "# Otherwise, the action column corresponding to the action at time t will be 1\n",
    "player_ids = df['player_id'].unique()\n",
    "for player_id in player_ids:\n",
    "    temp_df =  pd.DataFrame(columns=columns)\n",
    "    temp_df['player_id'] = [player_id]*((max_time-min_time)+1)\n",
    "    temp_df['time'] = np.arange(min_time, max_time+1)\n",
    "    temp_df = temp_df.fillna(0)\n",
    "    # perform one hot encoding of action at respective times\n",
    "    player_df = searchDF(df, [('player_id', player_id)])\n",
    "    for index, row in player_df.iterrows():\n",
    "        action = row['action']\n",
    "        time = row['time']\n",
    "        temp_df.loc[temp_df['time'] == time, action_df['action'][action]] = 1\n",
    "    new_df = pd.concat([new_df, temp_df], ignore_index=True)\n",
    "new_df.to_csv('matches/match_0/match_data_causal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_folder = 'matches/match_0/links'\n",
    "\n",
    "link_files = [os.path.join(links_folder, file) for file in os.listdir(links_folder)]\n",
    "\n",
    "link_dfs = [pd.read_csv(file) for file in link_files]\n",
    "\n",
    "# Combine all DataFrames\n",
    "combined_df = pd.concat(link_dfs, ignore_index=True)\n",
    "\n",
    "# Define aggregation rules\n",
    "def aggregate_links(group):\n",
    "    # Define priority hierarchy for link types\n",
    "    priority_order = [\n",
    "        # Highest priority: Directed links\n",
    "        '-->', '<--', '<->',\n",
    "        # Medium priority: Partially directed links\n",
    "        'o->', '<-o', 'x->', '<-x', '<-+', '+->',\n",
    "        # Lower priority: Confounded links\n",
    "        'x-o', 'o-x', 'x--', '--x', 'x-x',\n",
    "        # Lowest priority: Undirected links\n",
    "        'o-o', 'o--', '--o', '---'\n",
    "    ]\n",
    "    \n",
    "    # Find the highest priority link type in the group\n",
    "    for link_type in priority_order:\n",
    "        if any(group['Link type i --- j'] == link_type):\n",
    "            selected_link_type = link_type\n",
    "            break\n",
    "    else:\n",
    "        # Default to '---' if no link type is found (should not happen)\n",
    "        selected_link_type = '---'\n",
    "    \n",
    "    # Average the strengths\n",
    "    avg_strength = round(group['Link value'].mean(), 5)\n",
    "    \n",
    "    return pd.Series({\n",
    "        'Link type i --- j': selected_link_type,\n",
    "        'Link value': avg_strength\n",
    "    })\n",
    "\n",
    "# Group by source, target, and lag, then aggregate\n",
    "aggregated_df = combined_df.groupby(['Variable i', 'Variable j', 'Time lag of i']).apply(aggregate_links).reset_index()\n",
    "\n",
    "# Save aggregated results\n",
    "aggregated_df.to_csv('matches/match_0/aggregated_links.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct graph and val_matrix\n",
    "import tigramite.plotting as tp\n",
    "\n",
    "def createEmptyMatrix(width, height, depth, initValue):\n",
    "    return np.full((width, height, depth), initValue)\n",
    "\n",
    "\n",
    "TAU_MAX = 5\n",
    "match_folder = 'match_0'\n",
    "graph = createEmptyMatrix(22, 22, TAU_MAX+1, '')\n",
    "val_matrix = createEmptyMatrix(22, 22, TAU_MAX+1, 0.0)\n",
    "actions = (pd.read_csv('fkeys/action.csv')['action']).tolist()\n",
    "links = pd.read_csv('matches/match_0/aggregated_links.csv')\n",
    "for index, row in links.iterrows():\n",
    "    i = row['Variable i']\n",
    "    j = row['Variable j']\n",
    "    tau = int(row['Time lag of i'])\n",
    "    link_type = row['Link type i --- j']\n",
    "    link_value = row['Link value']\n",
    "    graph[actions.index(i)][actions.index(j)][tau] = link_type\n",
    "    val_matrix[actions.index(i)][actions.index(j)][tau] = link_value\n",
    "    val_matrix[actions.index(j)][actions.index(i)][tau] = link_value\n",
    "    \n",
    "tp.plot_graph(\n",
    "    val_matrix=val_matrix,\n",
    "    graph=graph,\n",
    "    var_names=actions,\n",
    "    link_colorbar_label='cross-MCI',\n",
    "    node_colorbar_label='auto-MCI',\n",
    "    show_autodependency_lags=False,\n",
    "    save_name=f'matches/{match_folder}/graph.png'\n",
    ")\n",
    "\n",
    "tp.plot_time_series_graph(\n",
    "    figsize=(6, 4),\n",
    "    val_matrix=val_matrix,\n",
    "    graph=graph,\n",
    "    var_names=actions,\n",
    "    link_colorbar_label='MCI',\n",
    "    save_name=f'matches/{match_folder}/time_series_graph.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# time, x_begin, y_begin, x_end, y_end, prev_action, time_lag, action(prediction)\n",
    "df = pd.read_csv('matches/match_0/match_data.csv')\n",
    "df = df.drop(columns=['id', 'event', 'action_result'])\n",
    "action_column = df['action']\n",
    "df = df.drop(columns=['action'])\n",
    "# Find the previous action that this player took and the time of that action\n",
    "prev_action = action_column.shift(1)\n",
    "prev_time = df['time'].shift(1)\n",
    "# Find the time difference between the current action and the previous action\n",
    "time_lag = df['time'] - prev_time\n",
    "df['prev_action'] = prev_action\n",
    "df['time_lag'] = time_lag\n",
    "# Drop the first row of each player\n",
    "players = df['player_id'].unique()\n",
    "for player in players:\n",
    "    indices = df[df['player_id'] == player].index\n",
    "    df = df.drop(indices[0])\n",
    "df = df.drop(columns=['time', 'player_id'])\n",
    "df['action'] = action_column\n",
    "df.to_csv('matches/match_0/match_data_gat.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
